{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88491,
     "status": "ok",
     "timestamp": 1723387139515,
     "user": {
      "displayName": "Shuvo Biswas",
      "userId": "02907278119849851588"
     },
     "user_tz": -360
    },
    "id": "GO6oD6g0HXcW",
    "outputId": "24f57d28-0f05-4d29-a2ae-6751b725353f"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U transformers peft accelerate optimum\n",
    "!pip install -q datasets==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5202,
     "status": "ok",
     "timestamp": 1723387211553,
     "user": {
      "displayName": "Shuvo Biswas",
      "userId": "02907278119849851588"
     },
     "user_tz": -360
    },
    "id": "N7GGVivvHtRM",
    "outputId": "fc5de760-ce4a-494d-b961-f91b824a6856"
   },
   "outputs": [],
   "source": [
    "!pip install -q auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10207,
     "status": "ok",
     "timestamp": 1723387228567,
     "user": {
      "displayName": "Shuvo Biswas",
      "userId": "02907278119849851588"
     },
     "user_tz": -360
    },
    "id": "YnqKFO3eHtFl",
    "outputId": "3d8baff2-2bda-4eca-e7c2-74869388d37a"
   },
   "outputs": [],
   "source": [
    "import torch, auto_gptq\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from auto_gptq.modeling import BaseGPTQForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1723387232724,
     "user": {
      "displayName": "Shuvo Biswas",
      "userId": "02907278119849851588"
     },
     "user_tz": -360
    },
    "id": "vwySxYzoIPxt",
    "outputId": "cac10e77-dbaa-44c2-a222-69de0a2ad5e9"
   },
   "outputs": [],
   "source": [
    "auto_gptq.modeling._base.SUPPORTED_MODELS = [\"internlm\"]\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sghF9Fd5IYk4"
   },
   "outputs": [],
   "source": [
    "class InternLMXComposer2QForCausalLM(BaseGPTQForCausalLM):\n",
    "    layers_block_name = \"model.layers\"\n",
    "    outside_layer_modules = [\n",
    "        'vit', 'vision_proj', 'model.tok_embeddings', 'model.norm', 'output',\n",
    "    ]\n",
    "    inside_layer_modules = [\n",
    "        [\"attention.wqkv.linear\"],\n",
    "        [\"attention.wo.linear\"],\n",
    "        [\"feed_forward.w1.linear\", \"feed_forward.w3.linear\"],\n",
    "        [\"feed_forward.w2.linear\"],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "error",
     "timestamp": 1723491063743,
     "user": {
      "displayName": "Naimur Rahman Khan Sifat",
      "userId": "17476774437598338283"
     },
     "user_tz": -360
    },
    "id": "qNIZ6n8FIeMD",
    "outputId": "09246c50-4e69-4062-d36f-41f9afdb98da"
   },
   "outputs": [],
   "source": [
    "model = InternLMXComposer2QForCausalLM.from_quantized(\n",
    "  'internlm/internlm-xcomposer2-7b-4bit', trust_remote_code=True, device=\"cuda:0\").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  'internlm/internlm-xcomposer2-7b-4bit', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhcJziTKtGI1"
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_z7ywjKKbda"
   },
   "outputs": [],
   "source": [
    "image_names=['/content/OR2.PNG','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "error",
     "timestamp": 1723386853451,
     "user": {
      "displayName": "Shuvo Biswas",
      "userId": "02907278119849851588"
     },
     "user_tz": -360
    },
    "id": "XFRywHF4tf6y",
    "outputId": "18aaf782-9961-4cfd-fa0b-f5e3e668382e"
   },
   "outputs": [],
   "source": [
    "for image_name in image_names:\n",
    "  img_path_list = [\n",
    "    image_name,\n",
    "  ]\n",
    "  images = []\n",
    "  for img_path in img_path_list:\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = model.vis_processor(image)\n",
    "    images.append(image)\n",
    "    image = torch.stack(images)\n",
    "  query = f'<ImageHere> <ImageHere> please explain the image.the image is based on {image_name}'\n",
    "  with torch.cuda.amp.autocast():\n",
    "    response, history = model.chat(tokenizer, query=query, image=image, history=[], do_sample=False)\n",
    "  print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "  print(response)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
